# -*- coding: utf-8 -*-
"""PinkSparklesCopulas-akshiBhasker

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/12o53Rwpu0MT2xiFIHpbhOCQXMx40hkVs
"""

import numpy as np

import pandas as pd

import matplotlib.pyplot as plt

import pylab

from scipy.stats import beta, lognorm, kendalltau, pearsonr, spearmanr, norm

from scipy.optimize import fmin

from scipy.integrate import quad

from scipy.special import expm1

#Calculate Kendall Correlation for pairs----we no using co-integration

import fix_yahoo_finance as yf

from pandas_datareader import data as pdr

import datetime

start_sp=datetime.datetime(2019,6,1)

end_sp=datetime.datetime(2020,1,1)

import pandas as pd

crypto_list=["ADA-USD", "BCH-USD", "ETH-USD", 'QTUM-USD']

crypto_data=pd.DataFrame

from scipy.stats import kendalltau

bch=pdr.get_data_yahoo('bch-usd', start_sp, end_sp)

bch=bch['Close']

eth=pdr.get_data_yahoo('eth-usd', start_sp, end_sp)

eth=eth['Close']

corr= kendalltau(bch,eth)

print('Kendall Rank correlation:' , corr)

# normal cumulative distribution

import scipy

import seaborn as sns

import matplotlib.pyplot as plt

import numpy as np

# we plot cumulative normal distributions of two stock prices

x=np.log(eth)
y=np.log(bch)

norm_eth=scipy.stats.norm.cdf(x)

norm_bch=scipy.stats.norm.cdf(y)

sns.lineplot(x=x, y=norm_eth)
plt.xlabel('Price')
plt.title('Normal Distribution of ETH')
plt.show()

sns.lineplot(x=y, y=norm_bch)
plt.xlabel('Price')
plt.title('Normal Distribution of BCH')
plt.show()

# we plot marginal distribution of stock prices.

def scatter_hist(x, y , ax, ax_histx, ax_histy):
    # no labels
    ax_histx.tick_params(axis="x", labelbottom=False)
    ax_histy.tick_params(axis="y", labelleft=False)

    # the scatter plot:
    ax.scatter(x, y)

# definitions for the axes
left, width = 0.1, 0.65
bottom, height = 0.1, 0.65
spacing = 0.005


rect_scatter = [left, bottom, width, height]
rect_histx = [left, bottom + height + spacing, width, 0.2]
rect_histy = [left + width + spacing, bottom, 0.2, height]

# start with a square Figure
fig = plt.figure(figsize=(8, 8))

ax = fig.add_axes(rect_scatter)
ax_histx = fig.add_axes(rect_histx, sharex=ax)
ax_histy = fig.add_axes(rect_histy, sharey=ax)

# use the previously defined function
scatter_hist(x, y, ax, ax_histx, ax_histy)

plt.show()

# we now plot kendall's tau according to grouped t-copula formula

out=np.arcsin(corr)

z=((2/3.14)*out)

plt.plot(z)

# make the t-copula in python

pip install copulalib

from copulalib.copulalib import Copula

def plotData():
    global x,y
    fig = plt.figure()
    fig.add_subplot(2,2,1)
    plt.hist(x,bins=20,color='pink',alpha=0.8,align='mid')
    plt.title('ETH-USD Distribution')
    fig.add_subplot(2,2,3)
    plt.scatter(x,y,marker="o",alpha=0.8)
    fig.add_subplot(2,2,4)
    plt.title('Joint X,Y')
    plt.hist(y,bins=20,orientation='horizontal',color='magenta',alpha=0.8,align='mid')
    plt.title('BCH-USD distribution')    
    plt.show()

plotData()

def generateCopulas():
    global x,y
    fig = plt.figure()
    frank = Copula(x,y,family='frank')
    uf,vf = frank.generate_uv(1000)
    fig.add_subplot(2,2,1)
    plt.scatter(uf,vf,marker='.',color='purple')
    plt.title('Frank copula')
    plt.show()

    clayton=Copula(x,y,family='clayton')
    uc,vc = clayton.generate_uv(1000)
    fig.add_subplot(2,2,2)
    plt.scatter(uc,vc,marker='.',color='pink')
    plt.title('Clayton copula')
    plt.show()

    gumbel=Copula(x,y,family='gumbel')
    ug,vg = gumbel.generate_uv(1000)
    fig.add_subplot(2,2,3)
    plt.scatter(ug,vg,marker='.',color='magenta')
    plt.title('Gumbel copula')
    plt.show()

generateCopulas()

## This is the modified t-copula with cholesky  decomposition formula

## Curerntly only claytom, gumbel and frank in-built functions are available, however with a sample size>300...it won't plot..Limitation

import numpy as np
import scipy.stats as stats
from scipy.linalg import sqrtm
from numpy.linalg import inv, cholesky
from scipy.stats import multivariate_normal, invgamma, t as student
import math

def simulate(copula, n):
    
        # We get correlation matrix from covariance matrix
        Sigma = copula.get_corr()
        D = sqrtm(np.diag(np.diag(Sigma)))
        Dinv = inv(D)
        P = np.dot(np.dot(Dinv, Sigma), Dinv)
        A = cholesky(P)
        
        for i in range(n):
            Z = np.random.normal(size=d)
            V = np.dot(A, Z)
            U = stats.norm.cdf(V)
            X.append(U)

        
        # LaplaceâStieltjes invert transform # not necessary but we need it 
        LSinv = { 'clayton' : lambda theta: np.random.gamma(shape=1./theta), 
                'gumbel' : lambda theta: stats.levy_stable.rvs(1./theta, 1., 0, math.cos(math.pi / (2 * theta))**theta), 
                'frank' : lambda theta: stats.logser.rvs(1. - math.exp(-theta)), 
                'amh' : lambda theta: stats.geom.rvs(theta)}

        for i in range(n):
            V = LSinv[copula.getFamily()](copula.get_parameter())
            X_i = [ copula.inverse_generator(-np.log(u) / V) for u in U[i, :] ]
            X.append(X_i)
            nu = copula.get_df()
            Sigma = copula.get_corr()

        for i in range(n):
            Z = multivariate_normal.rvs(size=1, cov=Sigma)
            W = invgamma.rvs(nu / 2., size=1)
            U = np.sqrt(W) * Z
            X_i = [ student.cdf(u, nu) for u in U ]
            X.append(X_i)

        return X

# now we fit this all to exit/entry points and implement it.
