""Automated Pair Testing - CRypto

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Ud51g1xaDJWxnel8o_doBMZ756w0ncz2
"""

import numpy as np

import pandas as pd

import seaborn as sns

import pandas.util.testing as tm

import matplotlib.pyplot as plt

from pykalman import KalmanFilter

pip install pykalman

from datetime import datetime

from math import sqrt

plt.figure(figsize=(20,8))
plt.title('Crypto and Price Values')
plt.xlabel('Time')
plt.ylabel('Price')
plt.plot(data1, label='ADA')
plt.plot(data2, label='BAT')
plt.plot(data3, label='BCH')
plt.plot(data4, label='VET')
plt.plot(data5, label='DASH')
plt.plot(data6 , label='XMR')
plt.plot(data7, label='XRP')
plt.plot(data8, label='ZEC')
plt.plot(data9, label='QTUM' )
plt.plot(data10, label='TRX')
plt.legend()
plt.show()

df_list=[]

from pandas_datareader import data as pdr

import datetime

import fix_yahoo_finance as yf

start_sp= datetime.datetime(2010,10,1)

end_sp=datetime.datetime(2019,10,1)

data1=pdr.get_data_yahoo('ADA-USD', start_sp, end_sp)

data2=pdr.get_data_yahoo('BAT-USD', start_sp, end_sp)

data3=pdr.get_data_yahoo('BCH-USD', start_sp, end_sp)

data4=pdr.get_data_yahoo('VET-USD', start_sp, end_sp)

data5=pdr.get_data_yahoo('DASH-USD', start_sp, end_sp)

data6=pdr.get_data_yahoo('XMR-USD', start_sp, end_sp)

data7=pdr.get_data_yahoo('XRP-USD', start_sp, end_sp)

data8=pdr.get_data_yahoo('MIOTA-USD', start_sp, end_sp)

data9=pdr.get_data_yahoo('ETH-USD', start_sp, end_sp)

data10=pdr.get_data_yahoo('ZEC-USD', start_sp, end_sp)

df_list.append(data1)

df_list.append(data2)

df_list.append(data3)

df_list.append(data4)

df_list.append(data5)

df_list.append(data6)

df_list.append(data7)

df_list.append(data8)

df_list.append(data9)

df_list.append(data10)

abc=list(df_list)

used_stocks=[]

vertical_stack = pd.concat([data1, data2, data3, data4, data5, data6, data7, data8, data9, data10], axis=0)

def find_cointegrated_pairs(dataframe, critial_level = 0.05):
    n = dataframe.shape[1] # the length of dateframe
    pvalue_matrix = np.ones((n, n)) # initialize the matrix of p
    keys = dataframe.columns # get the column names
    pairs = [] # initilize the list for cointegration
    for i in range(n):
        for j in range(i+1, n): # for j bigger than i
            stock1 = dataframe[keys[i]] # obtain the price of "stock1"
            stock2 = dataframe[keys[j]]# obtain the price of "stock2"
            result = sm.tsa.stattools.coint(stock1, stock2) # get conintegration
            pvalue = result[1] # get the pvalue
            pvalue_matrix[i, j] = pvalue
            if pvalue < critial_level: # if p-value less than the critical level
                pairs.append((keys[i], keys[j], pvalue)) # record the contract with that p-value
    return pvalue_matrix, pairs

import statsmodels.api as sm

#set up the split point for our "training data" on which to perform the co-integration test (the remaining dat awill be fed to our backtest function)
split = int(len(vertical_stack) * .4)
#run our dataframe (up to the split point) of ticker price data through our co-integration function and store results
pvalue_matrix,pairs = find_cointegrated_pairs(vertical_stack[:split])
#convert our matrix of stored results into a DataFrame
pvalue_matrix_df = pd.DataFrame(pvalue_matrix)
#use Seaborn to plot a heatmap of our results matrix
fig, ax = plt.subplots(figsize=(15,10))
sns.heatmap(pvalue_matrix_df,xticklabels=vertical_stack,yticklabels=vertical_stack,ax=ax)

def KalmanFilterAverage(x):
  # Construct a Kalman filter
    kf = KalmanFilter(transition_matrices = [1],
    observation_matrices = [1],
    initial_state_mean = 0,
    initial_state_covariance = 1,
    observation_covariance=1,
    transition_covariance=.01)
  # Use the observed values of the price to get a rolling mean
    state_means, _ = kf.filter(x.values)
    state_means = pd.Series(state_means.flatten(), index=x.index)
    return state_means
# Kalman filter regression
def KalmanFilterRegression(x,y):
    delta = 1e-3
    trans_cov = delta / (1 - delta) * np.eye(2) # How much random walk wiggles
    obs_mat = np.expand_dims(np.vstack([[x], [np.ones(len(x))]]).T, axis=1)
    kf = KalmanFilter(n_dim_obs=1, n_dim_state=2, # y is 1-dimensional, (alpha, beta) is 2-dimensional
    initial_state_mean=[0,0],
    initial_state_covariance=np.ones((2, 2)),
    transition_matrices=np.eye(2),
    observation_matrices=obs_mat,
    observation_covariance=2,
    transition_covariance=trans_cov)
    # Use the observations y to get running estimates and errors for the state parameters
    state_means, state_covs = kf.filter(y.values)
    return state_means
def half_life(spread):
    spread_lag = spread.shift(1)
    spread_lag.iloc[0] = spread_lag.iloc[1]
    spread_ret = spread - spread_lag
    spread_ret.iloc[0] = spread_ret.iloc[1]
    spread_lag2 = sm.add_constant(spread_lag)
    model = sm.OLS(spread_ret,spread_lag2)
    res = model.fit()
    halflife = int(round(-np.log(2) / res.params[1],0))
    if halflife <= 0:
        halflife = 1
    return halflife

import pandas_datareader.data as web
import datetime
import pandas as pd
from pandas.util.testing import assert_frame_equal

ewma = pd.Series.ewm
start = datetime.datetime(2018, 2, 8)
end = datetime.datetime(2019, 2, 8)
stock = 'BA'
price = web.DataReader(stock,'yahoo', start, end)

n = 14

def RSI(series,n):    
    delta = series.diff()
    u = delta * 0 
    d = u.copy()
    i_pos = delta > 0
    i_neg = delta < 0
    u[i_pos] = delta[i_pos]
    d[i_neg] = delta[i_neg]
    rs = ewma(u, span=n).mean() / ewma(d, span=n).mean()
    return 100 - 100 / (1 + rs)

print(RSI(price.Close,n))

dUp= delta[delta > 0]
dDown= delta[delta < 0]
#also you need something like:

RolUp = RolUp.reindex_like(delta, method='ffill')
RolDown = RolDown.reindex_like(delta, method='ffill')
otherwise RS = RolUp / RolDown will not do what you desire

#Edit: seems this is a more accurate way of RS calculation:

# dUp= delta[delta > 0]
# dDown= delta[delta < 0]

# dUp = dUp.reindex_like(delta, fill_value=0)
# dDown = dDown.reindex_like(delta, fill_value=0)

dUp, dDown = delta.copy(), delta.copy()
dUp[dUp < 0] = 0
dDown[dDown > 0] = 0

RolUp = pd.rolling_mean(dUp, n)
RolDown = pd.rolling_mean(dDown, n).abs()

rsi = RolUp / RolDown

